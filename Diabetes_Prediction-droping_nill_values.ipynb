{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing dataset using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('E:\\DataSet_Ayushi\\DiabetesPrediction-master\\DiabetesPrediction-master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "robust_scaler=RobustScaler()\n",
    "df=pd.read_csv('diabetes_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Glucose\"].replace(0,np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"].replace(0,np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"BMI\"].replace(0,np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"BloodPressure\"].replace(0,np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                  0\n",
       "Glucose                      5\n",
       "BloodPressure               35\n",
       "SkinThickness                0\n",
       "Insulin                      0\n",
       "BMI                         11\n",
       "DiabetesPedigreeFunction     0\n",
       "Age                          0\n",
       "Outcome                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if there is any missing values\n",
    "miss_val=df.isna().sum()\n",
    "miss_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all the values corresponding to the colimns are 0,Therefore there is no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"Glucose\"],how=\"all\",inplace=True)\n",
    "df.dropna(subset=[\"BMI\"],how=\"all\",inplace=True)\n",
    "df.dropna(subset=[\"BloodPressure\"],how=\"all\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(724, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>110.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>168.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>139.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1.441</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>189.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>23</td>\n",
       "      <td>846</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>166.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>19</td>\n",
       "      <td>175</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.587</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>47</td>\n",
       "      <td>230</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>107.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>103.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38</td>\n",
       "      <td>83</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>115.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>126.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>41</td>\n",
       "      <td>235</td>\n",
       "      <td>39.3</td>\n",
       "      <td>0.704</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8</td>\n",
       "      <td>99.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.4</td>\n",
       "      <td>0.388</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>196.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.451</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9</td>\n",
       "      <td>119.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.263</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11</td>\n",
       "      <td>143.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>33</td>\n",
       "      <td>146</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>125.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26</td>\n",
       "      <td>115</td>\n",
       "      <td>31.1</td>\n",
       "      <td>0.205</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>147.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.4</td>\n",
       "      <td>0.257</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>15</td>\n",
       "      <td>140</td>\n",
       "      <td>23.2</td>\n",
       "      <td>0.487</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13</td>\n",
       "      <td>145.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>19</td>\n",
       "      <td>110</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>117.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.1</td>\n",
       "      <td>0.337</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5</td>\n",
       "      <td>109.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.546</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>158.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>36</td>\n",
       "      <td>245</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.851</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>88.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>11</td>\n",
       "      <td>54</td>\n",
       "      <td>24.8</td>\n",
       "      <td>0.267</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>17</td>\n",
       "      <td>160</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.453</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>1</td>\n",
       "      <td>102.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0.293</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>11</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>37</td>\n",
       "      <td>150</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.785</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>3</td>\n",
       "      <td>102.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>20</td>\n",
       "      <td>94</td>\n",
       "      <td>30.8</td>\n",
       "      <td>0.400</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>1</td>\n",
       "      <td>109.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>18</td>\n",
       "      <td>116</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.219</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>9</td>\n",
       "      <td>140.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0.734</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>13</td>\n",
       "      <td>153.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>37</td>\n",
       "      <td>140</td>\n",
       "      <td>40.6</td>\n",
       "      <td>1.174</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>12</td>\n",
       "      <td>100.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>33</td>\n",
       "      <td>105</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>1</td>\n",
       "      <td>147.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>49.3</td>\n",
       "      <td>0.358</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>41</td>\n",
       "      <td>57</td>\n",
       "      <td>46.3</td>\n",
       "      <td>1.096</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>3</td>\n",
       "      <td>187.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>22</td>\n",
       "      <td>200</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.408</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>6</td>\n",
       "      <td>162.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.178</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>4</td>\n",
       "      <td>136.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>1.182</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>1</td>\n",
       "      <td>121.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>39</td>\n",
       "      <td>74</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.261</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>3</td>\n",
       "      <td>108.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.223</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>44</td>\n",
       "      <td>510</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.222</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>8</td>\n",
       "      <td>154.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.443</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>1</td>\n",
       "      <td>128.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>39</td>\n",
       "      <td>110</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1.057</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>7</td>\n",
       "      <td>137.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.391</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0.258</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>1</td>\n",
       "      <td>106.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>0.197</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.278</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>9</td>\n",
       "      <td>170.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>9</td>\n",
       "      <td>89.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.142</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>724 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6    148.0           72.0             35        0  33.6   \n",
       "1              1     85.0           66.0             29        0  26.6   \n",
       "2              8    183.0           64.0              0        0  23.3   \n",
       "3              1     89.0           66.0             23       94  28.1   \n",
       "4              0    137.0           40.0             35      168  43.1   \n",
       "5              5    116.0           74.0              0        0  25.6   \n",
       "6              3     78.0           50.0             32       88  31.0   \n",
       "8              2    197.0           70.0             45      543  30.5   \n",
       "10             4    110.0           92.0              0        0  37.6   \n",
       "11            10    168.0           74.0              0        0  38.0   \n",
       "12            10    139.0           80.0              0        0  27.1   \n",
       "13             1    189.0           60.0             23      846  30.1   \n",
       "14             5    166.0           72.0             19      175  25.8   \n",
       "16             0    118.0           84.0             47      230  45.8   \n",
       "17             7    107.0           74.0              0        0  29.6   \n",
       "18             1    103.0           30.0             38       83  43.3   \n",
       "19             1    115.0           70.0             30       96  34.6   \n",
       "20             3    126.0           88.0             41      235  39.3   \n",
       "21             8     99.0           84.0              0        0  35.4   \n",
       "22             7    196.0           90.0              0        0  39.8   \n",
       "23             9    119.0           80.0             35        0  29.0   \n",
       "24            11    143.0           94.0             33      146  36.6   \n",
       "25            10    125.0           70.0             26      115  31.1   \n",
       "26             7    147.0           76.0              0        0  39.4   \n",
       "27             1     97.0           66.0             15      140  23.2   \n",
       "28            13    145.0           82.0             19      110  22.2   \n",
       "29             5    117.0           92.0              0        0  34.1   \n",
       "30             5    109.0           75.0             26        0  36.0   \n",
       "31             3    158.0           76.0             36      245  31.6   \n",
       "32             3     88.0           58.0             11       54  24.8   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "738            2     99.0           60.0             17      160  36.6   \n",
       "739            1    102.0           74.0              0        0  39.5   \n",
       "740           11    120.0           80.0             37      150  42.3   \n",
       "741            3    102.0           44.0             20       94  30.8   \n",
       "742            1    109.0           58.0             18      116  28.5   \n",
       "743            9    140.0           94.0              0        0  32.7   \n",
       "744           13    153.0           88.0             37      140  40.6   \n",
       "745           12    100.0           84.0             33      105  30.0   \n",
       "746            1    147.0           94.0             41        0  49.3   \n",
       "747            1     81.0           74.0             41       57  46.3   \n",
       "748            3    187.0           70.0             22      200  36.4   \n",
       "749            6    162.0           62.0              0        0  24.3   \n",
       "750            4    136.0           70.0              0        0  31.2   \n",
       "751            1    121.0           78.0             39       74  39.0   \n",
       "752            3    108.0           62.0             24        0  26.0   \n",
       "753            0    181.0           88.0             44      510  43.3   \n",
       "754            8    154.0           78.0             32        0  32.4   \n",
       "755            1    128.0           88.0             39      110  36.5   \n",
       "756            7    137.0           90.0             41        0  32.0   \n",
       "757            0    123.0           72.0              0        0  36.3   \n",
       "758            1    106.0           76.0              0        0  37.5   \n",
       "759            6    190.0           92.0              0        0  35.5   \n",
       "760            2     88.0           58.0             26       16  28.4   \n",
       "761            9    170.0           74.0             31        0  44.0   \n",
       "762            9     89.0           62.0              0        0  22.5   \n",
       "763           10    101.0           76.0             48      180  32.9   \n",
       "764            2    122.0           70.0             27        0  36.8   \n",
       "765            5    121.0           72.0             23      112  26.2   \n",
       "766            1    126.0           60.0              0        0  30.1   \n",
       "767            1     93.0           70.0             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "5                       0.201   30        0  \n",
       "6                       0.248   26        1  \n",
       "8                       0.158   53        1  \n",
       "10                      0.191   30        0  \n",
       "11                      0.537   34        1  \n",
       "12                      1.441   57        0  \n",
       "13                      0.398   59        1  \n",
       "14                      0.587   51        1  \n",
       "16                      0.551   31        1  \n",
       "17                      0.254   31        1  \n",
       "18                      0.183   33        0  \n",
       "19                      0.529   32        1  \n",
       "20                      0.704   27        0  \n",
       "21                      0.388   50        0  \n",
       "22                      0.451   41        1  \n",
       "23                      0.263   29        1  \n",
       "24                      0.254   51        1  \n",
       "25                      0.205   41        1  \n",
       "26                      0.257   43        1  \n",
       "27                      0.487   22        0  \n",
       "28                      0.245   57        0  \n",
       "29                      0.337   38        0  \n",
       "30                      0.546   60        0  \n",
       "31                      0.851   28        1  \n",
       "32                      0.267   22        0  \n",
       "..                        ...  ...      ...  \n",
       "738                     0.453   21        0  \n",
       "739                     0.293   42        1  \n",
       "740                     0.785   48        1  \n",
       "741                     0.400   26        0  \n",
       "742                     0.219   22        0  \n",
       "743                     0.734   45        1  \n",
       "744                     1.174   39        0  \n",
       "745                     0.488   46        0  \n",
       "746                     0.358   27        1  \n",
       "747                     1.096   32        0  \n",
       "748                     0.408   36        1  \n",
       "749                     0.178   50        1  \n",
       "750                     1.182   22        1  \n",
       "751                     0.261   28        0  \n",
       "752                     0.223   25        0  \n",
       "753                     0.222   26        1  \n",
       "754                     0.443   45        1  \n",
       "755                     1.057   37        1  \n",
       "756                     0.391   39        0  \n",
       "757                     0.258   52        1  \n",
       "758                     0.197   26        0  \n",
       "759                     0.278   66        1  \n",
       "760                     0.766   22        0  \n",
       "761                     0.403   43        1  \n",
       "762                     0.142   33        0  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[724 rows x 9 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Models for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Logistic Regression is  0.7681818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Building Logistic Regression Model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR=LogisticRegression()\n",
    "# Creating Training DataSets\n",
    "X_train1=df.iloc[154:,0:8]\n",
    "Y_train1=df.iloc[154:,8:9]\n",
    "X_train2=df.iloc[0:154,0:8].append(df.iloc[308:,0:8])\n",
    "Y_train2=df.iloc[0:154,8:9].append(df.iloc[308:,8:9])\n",
    "X_train3=df.iloc[0:308,0:8].append(df.iloc[462:,0:8])\n",
    "Y_train3=df.iloc[0:308,8:9].append(df.iloc[462:,8:9])\n",
    "X_train4=df.iloc[0:462,0:8].append(df.iloc[616:,0:8])\n",
    "Y_train4=df.iloc[0:462,8:9].append(df.iloc[616:,8:9])\n",
    "X_train5=df.iloc[0:616,0:8]\n",
    "Y_train5=df.iloc[0:616,8:9]\n",
    "\n",
    "# Creating Test Dataset\n",
    "X_test1=df.iloc[0:154,0:8]\n",
    "Y_test1=df.iloc[0:154,8:9]\n",
    "X_test2=df.iloc[154:308,0:8]\n",
    "Y_test2=df.iloc[154:308,8:9]\n",
    "X_test3=df.iloc[308:462,0:8]\n",
    "Y_test3=df.iloc[308:462,8:9]\n",
    "X_test4=df.iloc[462:616,0:8]\n",
    "Y_test4=df.iloc[462:616,8:9]\n",
    "X_test5=df.iloc[616:,0:8]\n",
    "Y_test5=df.iloc[616:,8:9]\n",
    "\n",
    "#scaling training data\n",
    "X_train1_sc=robust_scaler.fit_transform(X_train1)\n",
    "Y_train1_sc=robust_scaler.fit_transform(Y_train1)\n",
    "X_train2_sc=robust_scaler.fit_transform(X_train2)\n",
    "Y_train2_sc=robust_scaler.fit_transform(Y_train2)\n",
    "X_train3_sc=robust_scaler.fit_transform(X_train3)\n",
    "Y_train3_sc=robust_scaler.fit_transform(Y_train3)\n",
    "X_train4_sc=robust_scaler.fit_transform(X_train4)\n",
    "Y_train4_sc=robust_scaler.fit_transform(Y_train4)\n",
    "X_train5_sc=robust_scaler.fit_transform(X_train5)\n",
    "Y_train5_sc=robust_scaler.fit_transform(Y_train5)\n",
    "\n",
    "#scaling test data\n",
    "X_test1_sc=robust_scaler.fit_transform(X_test1)\n",
    "Y_test1_sc=robust_scaler.fit_transform(Y_test1)\n",
    "X_test2_sc=robust_scaler.fit_transform(X_test2)\n",
    "Y_test2_sc=robust_scaler.fit_transform(Y_test2)\n",
    "X_test3_sc=robust_scaler.fit_transform(X_test3)\n",
    "Y_test3_sc=robust_scaler.fit_transform(Y_test3)\n",
    "X_test4_sc=robust_scaler.fit_transform(X_test4)\n",
    "Y_test4_sc=robust_scaler.fit_transform(Y_test4)\n",
    "X_test5_sc=robust_scaler.fit_transform(X_test5)\n",
    "Y_test5_sc=robust_scaler.fit_transform(Y_test5)\n",
    "\n",
    "\n",
    "# Training Model with Different Training Data\n",
    "LR_1=LR.fit(X_train1,Y_train1)\n",
    "LR_2=LR.fit(X_train2,Y_train2)\n",
    "LR_3=LR.fit(X_train3,Y_train3)\n",
    "LR_4=LR.fit(X_train4,Y_train4)\n",
    "LR_5=LR.fit(X_train5,Y_train5)\n",
    "\n",
    "\n",
    "# Predicting Values for Test Data\n",
    "pred_1=LR.predict(X_test1)\n",
    "pred_2=LR.predict(X_test2)\n",
    "pred_3=LR.predict(X_test3)\n",
    "pred_4=LR.predict(X_test4)\n",
    "pred_5=LR.predict(X_test5)\n",
    "\n",
    "# Calculating Accuracy Each Test Case and Hence Calculating Overall Accuracy of Model\n",
    "acc1=accuracy_score(Y_test1,pred_1)\n",
    "acc2=accuracy_score(Y_test2,pred_2)\n",
    "acc3=accuracy_score(Y_test3,pred_3)\n",
    "acc4=accuracy_score(Y_test4,pred_4)\n",
    "acc5=accuracy_score(Y_test5,pred_5)\n",
    "print('The accuracy of Logistic Regression is ',(acc1+acc2+acc3+acc4+acc5)/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Linear SVM  is  0.7733766233766233\n"
     ]
    }
   ],
   "source": [
    "# Applying Support vector Machine Algorithm with Linear Kernel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "svclassifier=SVC(kernel='linear')\n",
    "# Creating Training DataSets\n",
    "X_train1=df.iloc[154:,0:8]\n",
    "Y_train1=df.iloc[154:,8:9]\n",
    "X_train2=df.iloc[0:154,0:8].append(df.iloc[308:,0:8])\n",
    "Y_train2=df.iloc[0:154,8:9].append(df.iloc[308:,8:9])\n",
    "X_train3=df.iloc[0:308,0:8].append(df.iloc[462:,0:8])\n",
    "Y_train3=df.iloc[0:308,8:9].append(df.iloc[462:,8:9])\n",
    "X_train4=df.iloc[0:462,0:8].append(df.iloc[616:,0:8])\n",
    "Y_train4=df.iloc[0:462,8:9].append(df.iloc[616:,8:9])\n",
    "X_train5=df.iloc[0:616,0:8]\n",
    "Y_train5=df.iloc[0:616,8:9]\n",
    "\n",
    "# Creating Test Dataset\n",
    "X_test1=df.iloc[0:154,0:8]\n",
    "Y_test1=df.iloc[0:154,8:9]\n",
    "X_test2=df.iloc[154:308,0:8]\n",
    "Y_test2=df.iloc[154:308,8:9]\n",
    "X_test3=df.iloc[308:462,0:8]\n",
    "Y_test3=df.iloc[308:462,8:9]\n",
    "X_test4=df.iloc[462:616,0:8]\n",
    "Y_test4=df.iloc[462:616,8:9]\n",
    "X_test5=df.iloc[616:,0:8]\n",
    "Y_test5=df.iloc[616:,8:9]\n",
    "\n",
    "#scaling training data\n",
    "X_train1_sc=robust_scaler.fit_transform(X_train1)\n",
    "Y_train1_sc=robust_scaler.fit_transform(Y_train1)\n",
    "X_train2_sc=robust_scaler.fit_transform(X_train2)\n",
    "Y_train2_sc=robust_scaler.fit_transform(Y_train2)\n",
    "X_train3_sc=robust_scaler.fit_transform(X_train3)\n",
    "Y_train3_sc=robust_scaler.fit_transform(Y_train3)\n",
    "X_train4_sc=robust_scaler.fit_transform(X_train4)\n",
    "Y_train4_sc=robust_scaler.fit_transform(Y_train4)\n",
    "X_train5_sc=robust_scaler.fit_transform(X_train5)\n",
    "Y_train5_sc=robust_scaler.fit_transform(Y_train5)\n",
    "\n",
    "#scaling test data\n",
    "X_test1_sc=robust_scaler.fit_transform(X_test1)\n",
    "Y_test1_sc=robust_scaler.fit_transform(Y_test1)\n",
    "X_test2_sc=robust_scaler.fit_transform(X_test2)\n",
    "Y_test2_sc=robust_scaler.fit_transform(Y_test2)\n",
    "X_test3_sc=robust_scaler.fit_transform(X_test3)\n",
    "Y_test3_sc=robust_scaler.fit_transform(Y_test3)\n",
    "X_test4_sc=robust_scaler.fit_transform(X_test4)\n",
    "Y_test4_sc=robust_scaler.fit_transform(Y_test4)\n",
    "X_test5_sc=robust_scaler.fit_transform(X_test5)\n",
    "Y_test5_sc=robust_scaler.fit_transform(Y_test5)\n",
    "\n",
    "\n",
    "# Training Model with Different Training Data\n",
    "SV_1=svclassifier.fit(X_train1,Y_train1)\n",
    "SV_2=svclassifier.fit(X_train2,Y_train2)\n",
    "SV_3=svclassifier.fit(X_train3,Y_train3)\n",
    "SV_4=svclassifier.fit(X_train4,Y_train4)\n",
    "SV_5=svclassifier.fit(X_train5,Y_train5)\n",
    "\n",
    "\n",
    "# Predicting Values for Test Data\n",
    "pred_1=SV_1.predict(X_test1)\n",
    "pred_2=SV_2.predict(X_test2)\n",
    "pred_3=SV_3.predict(X_test3)\n",
    "pred_4=SV_4.predict(X_test4)\n",
    "pred_5=SV_5.predict(X_test5)\n",
    "\n",
    "\n",
    "# Calculating Accuracy Each Test Case and Hence Calculating Overall Accuracy of Model\n",
    "acc1=accuracy_score(Y_test1,pred_1)\n",
    "acc2=accuracy_score(Y_test2,pred_2)\n",
    "acc3=accuracy_score(Y_test3,pred_3)\n",
    "acc4=accuracy_score(Y_test4,pred_4)\n",
    "acc5=accuracy_score(Y_test5,pred_5)\n",
    "\n",
    "print('The accuracy of Linear SVM  is ',(acc1+acc2+acc3+acc4+acc5)/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Gaussian SVM is  0.9289473684210525\n"
     ]
    }
   ],
   "source": [
    "# Applying Support vector Machine Algorithm with Gaussian Kernel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "svclassifier=SVC(kernel='rbf')\n",
    "# Creating Training DataSets\n",
    "X_train1=df.iloc[154:,0:8]\n",
    "Y_train1=df.iloc[154:,8:9]\n",
    "X_train2=df.iloc[0:154,0:8].append(df.iloc[308:,0:8])\n",
    "Y_train2=df.iloc[0:154,8:9].append(df.iloc[308:,8:9])\n",
    "X_train3=df.iloc[0:308,0:8].append(df.iloc[462:,0:8])\n",
    "Y_train3=df.iloc[0:308,8:9].append(df.iloc[462:,8:9])\n",
    "X_train4=df.iloc[0:462,0:8].append(df.iloc[616:,0:8])\n",
    "Y_train4=df.iloc[0:462,8:9].append(df.iloc[616:,8:9])\n",
    "X_train5=df.iloc[0:616,0:8]\n",
    "Y_train5=df.iloc[0:616,8:9]\n",
    "\n",
    "# Creating Test Dataset\n",
    "X_test1=df.iloc[0:154,0:8]\n",
    "Y_test1=df.iloc[0:154,8:9]\n",
    "X_test2=df.iloc[154:308,0:8]\n",
    "Y_test2=df.iloc[154:308,8:9]\n",
    "X_test3=df.iloc[308:462,0:8]\n",
    "Y_test3=df.iloc[308:462,8:9]\n",
    "X_test4=df.iloc[462:616,0:8]\n",
    "Y_test4=df.iloc[462:616,8:9]\n",
    "X_test5=df.iloc[616:,0:8]\n",
    "Y_test5=df.iloc[616:,8:9]\n",
    "\n",
    "#scaling training data\n",
    "X_train1_sc=robust_scaler.fit_transform(X_train1)\n",
    "Y_train1_sc=robust_scaler.fit_transform(Y_train1)\n",
    "X_train2_sc=robust_scaler.fit_transform(X_train2)\n",
    "Y_train2_sc=robust_scaler.fit_transform(Y_train2)\n",
    "X_train3_sc=robust_scaler.fit_transform(X_train3)\n",
    "Y_train3_sc=robust_scaler.fit_transform(Y_train3)\n",
    "X_train4_sc=robust_scaler.fit_transform(X_train4)\n",
    "Y_train4_sc=robust_scaler.fit_transform(Y_train4)\n",
    "X_train5_sc=robust_scaler.fit_transform(X_train5)\n",
    "Y_train5_sc=robust_scaler.fit_transform(Y_train5)\n",
    "\n",
    "#scaling test data\n",
    "X_test1_sc=robust_scaler.fit_transform(X_test1)\n",
    "Y_test1_sc=robust_scaler.fit_transform(Y_test1)\n",
    "X_test2_sc=robust_scaler.fit_transform(X_test2)\n",
    "Y_test2_sc=robust_scaler.fit_transform(Y_test2)\n",
    "X_test3_sc=robust_scaler.fit_transform(X_test3)\n",
    "Y_test3_sc=robust_scaler.fit_transform(Y_test3)\n",
    "X_test4_sc=robust_scaler.fit_transform(X_test4)\n",
    "Y_test4_sc=robust_scaler.fit_transform(Y_test4)\n",
    "X_test5_sc=robust_scaler.fit_transform(X_test5)\n",
    "Y_test5_sc=robust_scaler.fit_transform(Y_test5)\n",
    "\n",
    "\n",
    "# Training Model with Different Training Data\n",
    "SV_1=svclassifier.fit(X_train1,Y_train1)\n",
    "SV_2=svclassifier.fit(X_train2,Y_train2)\n",
    "SV_3=svclassifier.fit(X_train3,Y_train3)\n",
    "SV_4=svclassifier.fit(X_train4,Y_train4)\n",
    "SV_5=svclassifier.fit(X_train5,Y_train5)\n",
    "\n",
    "\n",
    "# Predicting Values for Test Data\n",
    "pred_1=SV_1.predict(X_test1)\n",
    "pred_2=SV_2.predict(X_test2)\n",
    "pred_3=SV_3.predict(X_test3)\n",
    "pred_4=SV_4.predict(X_test4)\n",
    "pred_5=SV_5.predict(X_test5)\n",
    "\n",
    "\n",
    "# Calculating Accuracy Each Test Case and Hence Calculating Overall Accuracy of Model\n",
    "acc1=accuracy_score(Y_test1,pred_1)\n",
    "acc2=accuracy_score(Y_test2,pred_2)\n",
    "acc3=accuracy_score(Y_test3,pred_3)\n",
    "acc4=accuracy_score(Y_test4,pred_4)\n",
    "acc5=accuracy_score(Y_test5,pred_5)\n",
    "\n",
    "print('The accuracy of Gaussian SVM is ',(acc1+acc2+acc3+acc4+acc5)/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Sigmoid SVM is  0.6510252904989747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Applying Support vector Machine Algorithm with Sigmoidal Kernel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "svclassifier=SVC(kernel='sigmoid')\n",
    "# Creating Training DataSets\n",
    "X_train1=df.iloc[154:,0:8]\n",
    "Y_train1=df.iloc[154:,8:9]\n",
    "X_train2=df.iloc[0:154,0:8].append(df.iloc[308:,0:8])\n",
    "Y_train2=df.iloc[0:154,8:9].append(df.iloc[308:,8:9])\n",
    "X_train3=df.iloc[0:308,0:8].append(df.iloc[462:,0:8])\n",
    "Y_train3=df.iloc[0:308,8:9].append(df.iloc[462:,8:9])\n",
    "X_train4=df.iloc[0:462,0:8].append(df.iloc[616:,0:8])\n",
    "Y_train4=df.iloc[0:462,8:9].append(df.iloc[616:,8:9])\n",
    "X_train5=df.iloc[0:616,0:8]\n",
    "Y_train5=df.iloc[0:616,8:9]\n",
    "\n",
    "# Creating Test Dataset\n",
    "X_test1=df.iloc[0:154,0:8]\n",
    "Y_test1=df.iloc[0:154,8:9]\n",
    "X_test2=df.iloc[154:308,0:8]\n",
    "Y_test2=df.iloc[154:308,8:9]\n",
    "X_test3=df.iloc[308:462,0:8]\n",
    "Y_test3=df.iloc[308:462,8:9]\n",
    "X_test4=df.iloc[462:616,0:8]\n",
    "Y_test4=df.iloc[462:616,8:9]\n",
    "X_test5=df.iloc[616:,0:8]\n",
    "Y_test5=df.iloc[616:,8:9]\n",
    "\n",
    "#scaling training data\n",
    "X_train1_sc=robust_scaler.fit_transform(X_train1)\n",
    "Y_train1_sc=robust_scaler.fit_transform(Y_train1)\n",
    "X_train2_sc=robust_scaler.fit_transform(X_train2)\n",
    "Y_train2_sc=robust_scaler.fit_transform(Y_train2)\n",
    "X_train3_sc=robust_scaler.fit_transform(X_train3)\n",
    "Y_train3_sc=robust_scaler.fit_transform(Y_train3)\n",
    "X_train4_sc=robust_scaler.fit_transform(X_train4)\n",
    "Y_train4_sc=robust_scaler.fit_transform(Y_train4)\n",
    "X_train5_sc=robust_scaler.fit_transform(X_train5)\n",
    "Y_train5_sc=robust_scaler.fit_transform(Y_train5)\n",
    "\n",
    "#scaling test data\n",
    "X_test1_sc=robust_scaler.fit_transform(X_test1)\n",
    "Y_test1_sc=robust_scaler.fit_transform(Y_test1)\n",
    "X_test2_sc=robust_scaler.fit_transform(X_test2)\n",
    "Y_test2_sc=robust_scaler.fit_transform(Y_test2)\n",
    "X_test3_sc=robust_scaler.fit_transform(X_test3)\n",
    "Y_test3_sc=robust_scaler.fit_transform(Y_test3)\n",
    "X_test4_sc=robust_scaler.fit_transform(X_test4)\n",
    "Y_test4_sc=robust_scaler.fit_transform(Y_test4)\n",
    "X_test5_sc=robust_scaler.fit_transform(X_test5)\n",
    "Y_test5_sc=robust_scaler.fit_transform(Y_test5)\n",
    "\n",
    "\n",
    "# Training Model with Different Training Data\n",
    "SV_1=svclassifier.fit(X_train1,Y_train1)\n",
    "SV_2=svclassifier.fit(X_train2,Y_train2)\n",
    "SV_3=svclassifier.fit(X_train3,Y_train3)\n",
    "SV_4=svclassifier.fit(X_train4,Y_train4)\n",
    "SV_5=svclassifier.fit(X_train5,Y_train5)\n",
    "\n",
    "\n",
    "# Predicting Values for Test Data\n",
    "pred_1=SV_1.predict(X_test1)\n",
    "pred_2=SV_2.predict(X_test2)\n",
    "pred_3=SV_3.predict(X_test3)\n",
    "pred_4=SV_4.predict(X_test4)\n",
    "pred_5=SV_5.predict(X_test5)\n",
    "\n",
    "\n",
    "# Calculating Accuracy Each Test Case and Hence Calculating Overall Accuracy of Model\n",
    "acc1=accuracy_score(Y_test1,pred_1)\n",
    "acc2=accuracy_score(Y_test2,pred_2)\n",
    "acc3=accuracy_score(Y_test3,pred_3)\n",
    "acc4=accuracy_score(Y_test4,pred_4)\n",
    "acc5=accuracy_score(Y_test5,pred_5)\n",
    "\n",
    "print('The accuracy of Sigmoid SVM is ',(acc1+acc2+acc3+acc4+acc5)/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Decision Tree is  0.9434210526315789\n"
     ]
    }
   ],
   "source": [
    "# Applying Decission Tree Algorithm \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "Tree=tree.DecisionTreeClassifier()\n",
    "# Creating Training DataSets\n",
    "X_train1=df.iloc[154:,0:8]\n",
    "Y_train1=df.iloc[154:,8:9]\n",
    "X_train2=df.iloc[0:154,0:8].append(df.iloc[308:,0:8])\n",
    "Y_train2=df.iloc[0:154,8:9].append(df.iloc[308:,8:9])\n",
    "X_train3=df.iloc[0:308,0:8].append(df.iloc[462:,0:8])\n",
    "Y_train3=df.iloc[0:308,8:9].append(df.iloc[462:,8:9])\n",
    "X_train4=df.iloc[0:462,0:8].append(df.iloc[616:,0:8])\n",
    "Y_train4=df.iloc[0:462,8:9].append(df.iloc[616:,8:9])\n",
    "X_train5=df.iloc[0:616,0:8]\n",
    "Y_train5=df.iloc[0:616,8:9]\n",
    "\n",
    "# Creating Test Dataset\n",
    "X_test1=df.iloc[0:154,0:8]\n",
    "Y_test1=df.iloc[0:154,8:9]\n",
    "X_test2=df.iloc[154:308,0:8]\n",
    "Y_test2=df.iloc[154:308,8:9]\n",
    "X_test3=df.iloc[308:462,0:8]\n",
    "Y_test3=df.iloc[308:462,8:9]\n",
    "X_test4=df.iloc[462:616,0:8]\n",
    "Y_test4=df.iloc[462:616,8:9]\n",
    "X_test5=df.iloc[616:,0:8]\n",
    "Y_test5=df.iloc[616:,8:9]\n",
    "\n",
    "#scaling training data\n",
    "X_train1_sc=robust_scaler.fit_transform(X_train1)\n",
    "Y_train1_sc=robust_scaler.fit_transform(Y_train1)\n",
    "X_train2_sc=robust_scaler.fit_transform(X_train2)\n",
    "Y_train2_sc=robust_scaler.fit_transform(Y_train2)\n",
    "X_train3_sc=robust_scaler.fit_transform(X_train3)\n",
    "Y_train3_sc=robust_scaler.fit_transform(Y_train3)\n",
    "X_train4_sc=robust_scaler.fit_transform(X_train4)\n",
    "Y_train4_sc=robust_scaler.fit_transform(Y_train4)\n",
    "X_train5_sc=robust_scaler.fit_transform(X_train5)\n",
    "Y_train5_sc=robust_scaler.fit_transform(Y_train5)\n",
    "\n",
    "#scaling test data\n",
    "X_test1_sc=robust_scaler.fit_transform(X_test1)\n",
    "Y_test1_sc=robust_scaler.fit_transform(Y_test1)\n",
    "X_test2_sc=robust_scaler.fit_transform(X_test2)\n",
    "Y_test2_sc=robust_scaler.fit_transform(Y_test2)\n",
    "X_test3_sc=robust_scaler.fit_transform(X_test3)\n",
    "Y_test3_sc=robust_scaler.fit_transform(Y_test3)\n",
    "X_test4_sc=robust_scaler.fit_transform(X_test4)\n",
    "Y_test4_sc=robust_scaler.fit_transform(Y_test4)\n",
    "X_test5_sc=robust_scaler.fit_transform(X_test5)\n",
    "Y_test5_sc=robust_scaler.fit_transform(Y_test5)\n",
    "\n",
    "# Training Model with Different Training Data\n",
    "T_1=Tree.fit(X_train1,Y_train1)\n",
    "T_2=Tree.fit(X_train2,Y_train2)\n",
    "T_3=Tree.fit(X_train3,Y_train3)\n",
    "T_4=Tree.fit(X_train4,Y_train4)\n",
    "T_5=Tree.fit(X_train5,Y_train5)\n",
    "\n",
    "\n",
    "# Predicting Values for Test Data\n",
    "pred_1=T_1.predict(X_test1)\n",
    "pred_2=T_2.predict(X_test2)\n",
    "pred_3=T_3.predict(X_test3)\n",
    "pred_4=T_4.predict(X_test4)\n",
    "pred_5=T_5.predict(X_test5)\n",
    "\n",
    "\n",
    "# Calculating Accuracy Each Test Case and Hence Calculating Overall Accuracy of Model\n",
    "acc1=accuracy_score(Y_test1,pred_1)\n",
    "acc2=accuracy_score(Y_test2,pred_2)\n",
    "acc3=accuracy_score(Y_test3,pred_3)\n",
    "acc4=accuracy_score(Y_test4,pred_4)\n",
    "acc5=accuracy_score(Y_test5,pred_5)\n",
    "\n",
    "print('The accuracy of Decision Tree is ',(acc1+acc2+acc3+acc4+acc5)/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting Grpah for different Accuracy values to find best value pf K\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train1=df.iloc[154:,0:8]\n",
    "Y_train1=df.iloc[154:,8:9]\n",
    "X_test1=df.iloc[0:154,0:8]\n",
    "Y_test1=df.iloc[0:154,8:9]\n",
    "List=[]\n",
    "for k in range(1,16):\n",
    "    Knn=KNeighborsClassifier(n_neighbors=k)\n",
    "    Knn.fit(X_train1,Y_train1)\n",
    "    pre=Knn.predict(X_test1)\n",
    "    acc=accuracy_score(Y_test1,pre)\n",
    "    List.append(acc)\n",
    "    acc=0\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1,16),List,'bo-')\n",
    "plt.xlabel('Value Of K')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " From the graph it is clear that maximum accuracy is given by k=13 and k=14. Therefore, we can take any of two value for Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of KNN is  0.7758885850991114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:54: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:56: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:57: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:58: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "# Applying KNN Algorithm with K=13\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "Knn=KNeighborsClassifier(n_neighbors=13)\n",
    "\n",
    "# Creating Training Datasets\n",
    "X_train1=df.iloc[154:,0:8]\n",
    "Y_train1=df.iloc[154:,8:9]\n",
    "X_train2=df.iloc[0:154,0:8].append(df.iloc[308:,0:8])\n",
    "Y_train2=df.iloc[0:154,8:9].append(df.iloc[308:,8:9])\n",
    "X_train3=df.iloc[0:308,0:8].append(df.iloc[462:,0:8])\n",
    "Y_train3=df.iloc[0:308,8:9].append(df.iloc[462:,8:9])\n",
    "X_train4=df.iloc[0:462,0:8].append(df.iloc[616:,0:8])\n",
    "Y_train4=df.iloc[0:462,8:9].append(df.iloc[616:,8:9])\n",
    "X_train5=df.iloc[0:616,0:8]\n",
    "Y_train5=df.iloc[0:616,8:9]\n",
    "\n",
    "# Creating Test Dataset\n",
    "X_test1=df.iloc[0:154,0:8]\n",
    "Y_test1=df.iloc[0:154,8:9]\n",
    "X_test2=df.iloc[154:308,0:8]\n",
    "Y_test2=df.iloc[154:308,8:9]\n",
    "X_test3=df.iloc[308:462,0:8]\n",
    "Y_test3=df.iloc[308:462,8:9]\n",
    "X_test4=df.iloc[462:616,0:8]\n",
    "Y_test4=df.iloc[462:616,8:9]\n",
    "X_test5=df.iloc[616:,0:8]\n",
    "Y_test5=df.iloc[616:,8:9]\n",
    "\n",
    "#scaling training data\n",
    "X_train1_sc=robust_scaler.fit_transform(X_train1)\n",
    "Y_train1_sc=robust_scaler.fit_transform(Y_train1)\n",
    "X_train2_sc=robust_scaler.fit_transform(X_train2)\n",
    "Y_train2_sc=robust_scaler.fit_transform(Y_train2)\n",
    "X_train3_sc=robust_scaler.fit_transform(X_train3)\n",
    "Y_train3_sc=robust_scaler.fit_transform(Y_train3)\n",
    "X_train4_sc=robust_scaler.fit_transform(X_train4)\n",
    "Y_train4_sc=robust_scaler.fit_transform(Y_train4)\n",
    "X_train5_sc=robust_scaler.fit_transform(X_train5)\n",
    "Y_train5_sc=robust_scaler.fit_transform(Y_train5)\n",
    "\n",
    "#scaling test data\n",
    "X_test1_sc=robust_scaler.fit_transform(X_test1)\n",
    "Y_test1_sc=robust_scaler.fit_transform(Y_test1)\n",
    "X_test2_sc=robust_scaler.fit_transform(X_test2)\n",
    "Y_test2_sc=robust_scaler.fit_transform(Y_test2)\n",
    "X_test3_sc=robust_scaler.fit_transform(X_test3)\n",
    "Y_test3_sc=robust_scaler.fit_transform(Y_test3)\n",
    "X_test4_sc=robust_scaler.fit_transform(X_test4)\n",
    "Y_test4_sc=robust_scaler.fit_transform(Y_test4)\n",
    "X_test5_sc=robust_scaler.fit_transform(X_test5)\n",
    "Y_test5_sc=robust_scaler.fit_transform(Y_test5)\n",
    "\n",
    "# Training Model with Different Training Data\n",
    "Knn_1=Knn.fit(X_train1,Y_train1)\n",
    "Knn_2=Knn.fit(X_train2,Y_train2)\n",
    "Knn_3=Knn.fit(X_train3,Y_train3)\n",
    "Knn_4=Knn.fit(X_train4,Y_train4)\n",
    "Knn_5=Knn.fit(X_train5,Y_train5)\n",
    "\n",
    "\n",
    "# Predicting Values for Test Data\n",
    "pred_1=Knn_1.predict(X_test1)\n",
    "pred_2=Knn_2.predict(X_test2)\n",
    "pred_3=Knn_3.predict(X_test3)\n",
    "pred_4=Knn_4.predict(X_test4)\n",
    "pred_5=Knn_5.predict(X_test5)\n",
    "\n",
    "\n",
    "# Calculating Accuracy Each Test Case and Hence Calculating Overall Accuracy of Model\n",
    "acc1=accuracy_score(Y_test1,pred_1)\n",
    "acc2=accuracy_score(Y_test2,pred_2)\n",
    "acc3=accuracy_score(Y_test3,pred_3)\n",
    "acc4=accuracy_score(Y_test4,pred_4)\n",
    "acc5=accuracy_score(Y_test5,pred_5)\n",
    "\n",
    "print('The accuracy of KNN is ',(acc1+acc2+acc3+acc4+acc5)/5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of KNN is  0.7694121667805878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:54: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:56: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:57: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:58: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "# Applying KNN Algorithm with K=14\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "Knn=KNeighborsClassifier(n_neighbors=14)\n",
    "\n",
    "# Creating Training Datasets\n",
    "X_train1=df.iloc[154:,0:8]\n",
    "Y_train1=df.iloc[154:,8:9]\n",
    "X_train2=df.iloc[0:154,0:8].append(df.iloc[308:,0:8])\n",
    "Y_train2=df.iloc[0:154,8:9].append(df.iloc[308:,8:9])\n",
    "X_train3=df.iloc[0:308,0:8].append(df.iloc[462:,0:8])\n",
    "Y_train3=df.iloc[0:308,8:9].append(df.iloc[462:,8:9])\n",
    "X_train4=df.iloc[0:462,0:8].append(df.iloc[616:,0:8])\n",
    "Y_train4=df.iloc[0:462,8:9].append(df.iloc[616:,8:9])\n",
    "X_train5=df.iloc[0:616,0:8]\n",
    "Y_train5=df.iloc[0:616,8:9]\n",
    "\n",
    "# Creating Test Dataset\n",
    "X_test1=df.iloc[0:154,0:8]\n",
    "Y_test1=df.iloc[0:154,8:9]\n",
    "X_test2=df.iloc[154:308,0:8]\n",
    "Y_test2=df.iloc[154:308,8:9]\n",
    "X_test3=df.iloc[308:462,0:8]\n",
    "Y_test3=df.iloc[308:462,8:9]\n",
    "X_test4=df.iloc[462:616,0:8]\n",
    "Y_test4=df.iloc[462:616,8:9]\n",
    "X_test5=df.iloc[616:,0:8]\n",
    "Y_test5=df.iloc[616:,8:9]\n",
    "\n",
    "#scaling training data\n",
    "X_train1_sc=robust_scaler.fit_transform(X_train1)\n",
    "Y_train1_sc=robust_scaler.fit_transform(Y_train1)\n",
    "X_train2_sc=robust_scaler.fit_transform(X_train2)\n",
    "Y_train2_sc=robust_scaler.fit_transform(Y_train2)\n",
    "X_train3_sc=robust_scaler.fit_transform(X_train3)\n",
    "Y_train3_sc=robust_scaler.fit_transform(Y_train3)\n",
    "X_train4_sc=robust_scaler.fit_transform(X_train4)\n",
    "Y_train4_sc=robust_scaler.fit_transform(Y_train4)\n",
    "X_train5_sc=robust_scaler.fit_transform(X_train5)\n",
    "Y_train5_sc=robust_scaler.fit_transform(Y_train5)\n",
    "\n",
    "#scaling test data\n",
    "X_test1_sc=robust_scaler.fit_transform(X_test1)\n",
    "Y_test1_sc=robust_scaler.fit_transform(Y_test1)\n",
    "X_test2_sc=robust_scaler.fit_transform(X_test2)\n",
    "Y_test2_sc=robust_scaler.fit_transform(Y_test2)\n",
    "X_test3_sc=robust_scaler.fit_transform(X_test3)\n",
    "Y_test3_sc=robust_scaler.fit_transform(Y_test3)\n",
    "X_test4_sc=robust_scaler.fit_transform(X_test4)\n",
    "Y_test4_sc=robust_scaler.fit_transform(Y_test4)\n",
    "X_test5_sc=robust_scaler.fit_transform(X_test5)\n",
    "Y_test5_sc=robust_scaler.fit_transform(Y_test5)\n",
    "\n",
    "# Training Model with Different Training Data\n",
    "Knn_1=Knn.fit(X_train1,Y_train1)\n",
    "Knn_2=Knn.fit(X_train2,Y_train2)\n",
    "Knn_3=Knn.fit(X_train3,Y_train3)\n",
    "Knn_4=Knn.fit(X_train4,Y_train4)\n",
    "Knn_5=Knn.fit(X_train5,Y_train5)\n",
    "\n",
    "\n",
    "# Predicting Values for Test Data\n",
    "pred_1=Knn_1.predict(X_test1)\n",
    "pred_2=Knn_2.predict(X_test2)\n",
    "pred_3=Knn_3.predict(X_test3)\n",
    "pred_4=Knn_4.predict(X_test4)\n",
    "pred_5=Knn_5.predict(X_test5)\n",
    "\n",
    "\n",
    "# Calculating Accuracy Each Test Case and Hence Calculating Overall Accuracy of Model\n",
    "acc1=accuracy_score(Y_test1,pred_1)\n",
    "acc2=accuracy_score(Y_test2,pred_2)\n",
    "acc3=accuracy_score(Y_test3,pred_3)\n",
    "acc4=accuracy_score(Y_test4,pred_4)\n",
    "acc5=accuracy_score(Y_test5,pred_5)\n",
    "\n",
    "print('The accuracy of KNN is ',(acc1+acc2+acc3+acc4+acc5)/5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Naive Bayes is  0.76296992481203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Applying Naive Bayes 'Gaussian' Algorithm \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb=GaussianNB()\n",
    "\n",
    "# Creating Training Datasets\n",
    "X_train1=df.iloc[154:,0:8]\n",
    "Y_train1=df.iloc[154:,8:9]\n",
    "X_train2=df.iloc[0:154,0:8].append(df.iloc[308:,0:8])\n",
    "Y_train2=df.iloc[0:154,8:9].append(df.iloc[308:,8:9])\n",
    "X_train3=df.iloc[0:308,0:8].append(df.iloc[462:,0:8])\n",
    "Y_train3=df.iloc[0:308,8:9].append(df.iloc[462:,8:9])\n",
    "X_train4=df.iloc[0:462,0:8].append(df.iloc[616:,0:8])\n",
    "Y_train4=df.iloc[0:462,8:9].append(df.iloc[616:,8:9])\n",
    "X_train5=df.iloc[0:616,0:8]\n",
    "Y_train5=df.iloc[0:616,8:9]\n",
    "\n",
    "# Creating Test Dataset\n",
    "X_test1=df.iloc[0:154,0:8]\n",
    "Y_test1=df.iloc[0:154,8:9]\n",
    "X_test2=df.iloc[154:308,0:8]\n",
    "Y_test2=df.iloc[154:308,8:9]\n",
    "X_test3=df.iloc[308:462,0:8]\n",
    "Y_test3=df.iloc[308:462,8:9]\n",
    "X_test4=df.iloc[462:616,0:8]\n",
    "Y_test4=df.iloc[462:616,8:9]\n",
    "X_test5=df.iloc[616:,0:8]\n",
    "Y_test5=df.iloc[616:,8:9]\n",
    "\n",
    "#scaling training data\n",
    "X_train1_sc=robust_scaler.fit_transform(X_train1)\n",
    "Y_train1_sc=robust_scaler.fit_transform(Y_train1)\n",
    "X_train2_sc=robust_scaler.fit_transform(X_train2)\n",
    "Y_train2_sc=robust_scaler.fit_transform(Y_train2)\n",
    "X_train3_sc=robust_scaler.fit_transform(X_train3)\n",
    "Y_train3_sc=robust_scaler.fit_transform(Y_train3)\n",
    "X_train4_sc=robust_scaler.fit_transform(X_train4)\n",
    "Y_train4_sc=robust_scaler.fit_transform(Y_train4)\n",
    "X_train5_sc=robust_scaler.fit_transform(X_train5)\n",
    "Y_train5_sc=robust_scaler.fit_transform(Y_train5)\n",
    "\n",
    "#scaling test data\n",
    "X_test1_sc=robust_scaler.fit_transform(X_test1)\n",
    "Y_test1_sc=robust_scaler.fit_transform(Y_test1)\n",
    "X_test2_sc=robust_scaler.fit_transform(X_test2)\n",
    "Y_test2_sc=robust_scaler.fit_transform(Y_test2)\n",
    "X_test3_sc=robust_scaler.fit_transform(X_test3)\n",
    "Y_test3_sc=robust_scaler.fit_transform(Y_test3)\n",
    "X_test4_sc=robust_scaler.fit_transform(X_test4)\n",
    "Y_test4_sc=robust_scaler.fit_transform(Y_test4)\n",
    "X_test5_sc=robust_scaler.fit_transform(X_test5)\n",
    "Y_test5_sc=robust_scaler.fit_transform(Y_test5)\n",
    "\n",
    "\n",
    "# Training Model with Different Training Data\n",
    "gnb_1=gnb.fit(X_train1,Y_train1)\n",
    "gnb_2=gnb.fit(X_train2,Y_train2)\n",
    "gnb_3=gnb.fit(X_train3,Y_train3)\n",
    "gnb_4=gnb.fit(X_train4,Y_train4)\n",
    "gnb_5=gnb.fit(X_train5,Y_train5)\n",
    "\n",
    "\n",
    "# Predicting Values for Test Data\n",
    "pred_1=gnb_1.predict(X_test1)\n",
    "pred_2=gnb_2.predict(X_test2)\n",
    "pred_3=gnb_3.predict(X_test3)\n",
    "pred_4=gnb_4.predict(X_test4)\n",
    "pred_5=gnb_5.predict(X_test5)\n",
    "\n",
    "\n",
    "# Calculating Accuracy Each Test Case and Hence Calculating Overall Accuracy of Model\n",
    "acc1=accuracy_score(Y_test1,pred_1)\n",
    "acc2=accuracy_score(Y_test2,pred_2)\n",
    "acc3=accuracy_score(Y_test3,pred_3)\n",
    "acc4=accuracy_score(Y_test4,pred_4)\n",
    "acc5=accuracy_score(Y_test5,pred_5)\n",
    "\n",
    "print('The accuracy of Naive Bayes is ',(acc1+acc2+acc3+acc4+acc5)/5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:56: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:57: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:58: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Random Forest is  0.927904989747095\n"
     ]
    }
   ],
   "source": [
    "# Applying Random Forest Algorithm \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "Rnf=RandomForestClassifier()\n",
    "\n",
    "# Creating Training Datasets\n",
    "X_train1=df.iloc[154:,0:8]\n",
    "Y_train1=df.iloc[154:,8:9]\n",
    "X_train2=df.iloc[0:154,0:8].append(df.iloc[308:,0:8])\n",
    "Y_train2=df.iloc[0:154,8:9].append(df.iloc[308:,8:9])\n",
    "X_train3=df.iloc[0:308,0:8].append(df.iloc[462:,0:8])\n",
    "Y_train3=df.iloc[0:308,8:9].append(df.iloc[462:,8:9])\n",
    "X_train4=df.iloc[0:462,0:8].append(df.iloc[616:,0:8])\n",
    "Y_train4=df.iloc[0:462,8:9].append(df.iloc[616:,8:9])\n",
    "X_train5=df.iloc[0:616,0:8]\n",
    "Y_train5=df.iloc[0:616,8:9]\n",
    "\n",
    "# Creating Test Dataset\n",
    "X_test1=df.iloc[0:154,0:8]\n",
    "Y_test1=df.iloc[0:154,8:9]\n",
    "X_test2=df.iloc[154:308,0:8]\n",
    "Y_test2=df.iloc[154:308,8:9]\n",
    "X_test3=df.iloc[308:462,0:8]\n",
    "Y_test3=df.iloc[308:462,8:9]\n",
    "X_test4=df.iloc[462:616,0:8]\n",
    "Y_test4=df.iloc[462:616,8:9]\n",
    "X_test5=df.iloc[616:,0:8]\n",
    "Y_test5=df.iloc[616:,8:9]\n",
    "\n",
    "#scaling training data\n",
    "X_train1_sc=robust_scaler.fit_transform(X_train1)\n",
    "Y_train1_sc=robust_scaler.fit_transform(Y_train1)\n",
    "X_train2_sc=robust_scaler.fit_transform(X_train2)\n",
    "Y_train2_sc=robust_scaler.fit_transform(Y_train2)\n",
    "X_train3_sc=robust_scaler.fit_transform(X_train3)\n",
    "Y_train3_sc=robust_scaler.fit_transform(Y_train3)\n",
    "X_train4_sc=robust_scaler.fit_transform(X_train4)\n",
    "Y_train4_sc=robust_scaler.fit_transform(Y_train4)\n",
    "X_train5_sc=robust_scaler.fit_transform(X_train5)\n",
    "Y_train5_sc=robust_scaler.fit_transform(Y_train5)\n",
    "\n",
    "#scaling test data\n",
    "X_test1_sc=robust_scaler.fit_transform(X_test1)\n",
    "Y_test1_sc=robust_scaler.fit_transform(Y_test1)\n",
    "X_test2_sc=robust_scaler.fit_transform(X_test2)\n",
    "Y_test2_sc=robust_scaler.fit_transform(Y_test2)\n",
    "X_test3_sc=robust_scaler.fit_transform(X_test3)\n",
    "Y_test3_sc=robust_scaler.fit_transform(Y_test3)\n",
    "X_test4_sc=robust_scaler.fit_transform(X_test4)\n",
    "Y_test4_sc=robust_scaler.fit_transform(Y_test4)\n",
    "X_test5_sc=robust_scaler.fit_transform(X_test5)\n",
    "Y_test5_sc=robust_scaler.fit_transform(Y_test5)\n",
    "\n",
    "\n",
    "# Training Model with Different Training Data\n",
    "Rnf_1=Rnf.fit(X_train1,Y_train1)\n",
    "Rnf_2=Rnf.fit(X_train2,Y_train2)\n",
    "Rnf_3=Rnf.fit(X_train3,Y_train3)\n",
    "Rnf_4=Rnf.fit(X_train4,Y_train4)\n",
    "Rnf_5=Rnf.fit(X_train5,Y_train5)\n",
    "\n",
    "\n",
    "# Predicting Values for Test Data\n",
    "pred_1=Rnf_1.predict(X_test1)\n",
    "pred_2=Rnf_2.predict(X_test2)\n",
    "pred_3=Rnf_3.predict(X_test3)\n",
    "pred_4=Rnf_4.predict(X_test4)\n",
    "pred_5=Rnf_5.predict(X_test5)\n",
    "\n",
    "\n",
    "# Calculating Accuracy Each Test Case and Hence Calculating Overall Accuracy of Model\n",
    "acc1=accuracy_score(Y_test1,pred_1)\n",
    "acc2=accuracy_score(Y_test2,pred_2)\n",
    "acc3=accuracy_score(Y_test3,pred_3)\n",
    "acc4=accuracy_score(Y_test4,pred_4)\n",
    "acc5=accuracy_score(Y_test5,pred_5)\n",
    "\n",
    "print('The accuracy of Random Forest is ',(acc1+acc2+acc3+acc4+acc5)/5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We have Use 6 Algorithms and thier accuracy are\n",
    "Logistic Regression => 78.5%\n",
    "SVM with Linear kernel => 77.5%\n",
    "SVM with Gaussian kernel => 92.8%\n",
    "SVM with Sigmoid kernel => 65.1%\n",
    "Decission Tree => 94.3%\n",
    "KNN with n=13 => 77.5%\n",
    "KNN with n=14 => 76.9%\n",
    "Naive Bayes => 76.2%\n",
    "Random Forest => 92.7%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thus, we will choose Decission Tree model which gives the maximum accuracy of 94.3%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
